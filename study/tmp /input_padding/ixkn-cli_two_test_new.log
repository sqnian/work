nohup: ignoring input
test op 

output_pt:tensor([0.1268, 0.0000, 0.2979, 0.2075, 0.0000, 0.0000, 0.1240, 0.0099, 0.0000,
        0.0629, 0.0126, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1216, 0.0000,
        0.0000, 0.4124, 0.3174, 0.2001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.1678, 0.0000, 0.1964, 0.1820, 0.0000, 0.0000, 0.2285, 0.0276, 0.0966,
        0.0000, 0.0000, 0.6958, 0.1216, 0.0000, 0.0997, 0.0000, 0.2795, 0.1609,
        0.0000, 0.0891, 0.2732, 0.0000, 0.0000, 0.0000, 0.0000, 0.1895, 0.3425,
        0.2578, 0.0000, 0.0000, 0.0000, 0.4500, 0.0000, 0.1271, 0.0106, 0.0602,
        0.0000, 0.2917, 0.0000, 0.1383, 0.0000, 0.0000, 0.1998, 0.0000, 0.0000,
        0.6367, 0.0000, 0.0000, 0.4355, 0.0000, 0.1749, 0.0000, 0.0000, 0.1642,
        0.4077, 0.0078, 0.0000, 0.4426, 0.0000, 0.1885, 0.1078, 0.1750, 0.0000,
        0.0000, 0.0273, 0.0922, 0.0000, 0.0000, 0.1260, 0.6016, 0.0000, 0.0000,
        0.0378], device='cuda:0', dtype=torch.float16,
       grad_fn=<SliceBackward0>)

output_pt shape:torch.Size([24, 176, 19, 256])
output_cu:tensor([0.1270, 0.0000, 0.2979, 0.2075, 0.0000, 0.0000, 0.1241, 0.0099, 0.0000,
        0.0628, 0.0126, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1216, 0.0000,
        0.0000, 0.4124, 0.3174, 0.2002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.1681, 0.0000, 0.1964, 0.1820, 0.0000, 0.0000, 0.2286, 0.0277, 0.0966,
        0.0000, 0.0000, 0.6958, 0.1216, 0.0000, 0.0996, 0.0000, 0.2793, 0.1610,
        0.0000, 0.0890, 0.2732, 0.0000, 0.0000, 0.0000, 0.0000, 0.1895, 0.3428,
        0.2576, 0.0000, 0.0000, 0.0000, 0.4500, 0.0000, 0.1270, 0.0106, 0.0602,
        0.0000, 0.2917, 0.0000, 0.1384, 0.0000, 0.0000, 0.1997, 0.0000, 0.0000,
        0.6367, 0.0000, 0.0000, 0.4355, 0.0000, 0.1750, 0.0000, 0.0000, 0.1642,
        0.4077, 0.0078, 0.0000, 0.4429, 0.0000, 0.1886, 0.1078, 0.1750, 0.0000,
        0.0000, 0.0272, 0.0921, 0.0000, 0.0000, 0.1260, 0.6016, 0.0000, 0.0000,
        0.0378], device='cuda:0', dtype=torch.float16)

output_cu :torch.Size([24, 176, 19, 256])

diff max:0.0009765625

==45362== IXKN-CLI is profiling process 45362, command: /usr/local/bin/python3 two_test_pad.py 
==45362== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==45362== Replaying kernel "void ker_input_pad<__half>(__half*, __half*, int, int, int, int)" (done)
==45362== Replaying kernel "void ker_weight_pad_trans<__half>(__half*, __half*, int)" (done)
==45362== Replaying kernel "void ker_output_data<__half>(__half*, __half*)" (done)
==45362== Profiling application: /usr/local/bin/python3 two_test_pad.py 
==45362== Profiling result:
==45362== Section Results:
  Kernel: void ker_input_pad<__half>(__half*, __half*, int, int, int, int), Context 1, Stream 1, correlationId 1076
    Section: GPU Speed Of Light
    ------------------------------------------------------------------------- ---------------- -------------
    Duration                                                                           4647.95 Us             
    Elapsed Cycles                                                                   363358208 Cycles         
    SPP Active Cycles                                                                356312170 Cycles         
    Scheduler(NS) Issue Cycles                                                         3130343 Cycles         
    ALU Active Cycles                                                                  3447885 Cycles         
    LSU Active Cycles                                                                353977398 Cycles         
    L1 Vector Cache Active Cycles                                                     89778128 Cycles         
    ------------------------------------------------------------------------- ---------------- -------------
    INF: High-level overview of the usage for compute and memory resources of the GPU.
    INF: High Throughput --- The kernel is utilizing greater than 80% of the available compute or memory
performance of the device. To further improve performance, work will likely need to be shifted from the
most utilized to another unit. Start by analyzing workloads in the Memory Access section.

    Section: Instruction Statistics
    ------------------------------------------------------------------------- ---------------- -------------
    Executed IPC                                                                      0.010436 Inst/Cycle     
    Executed Instructions                                                              3793536 Instructions   
    Single-Lane Memory Instructions                                                      63936 Instructions   
    Single-Lane ALU Instructions                                                       1662336 Instructions   
    Single-Lane Control Flow Instructions                                               213120 Instructions   
    Multi-Lane Memory Instructions                                                       42624 Instructions   
     -Multi-Lane Global Memory Instructions                                              42624 Instructions   
     -Multi-Lane Shared Memory Instructions                                                  0 Instructions   
     -Multi-Lane SME Memory Instructions                                                     0 Instructions   
    Multi-Lane ALU Instructions                                                        1811520 Instructions   
     -Multi-Lane ALU Integer Instructions                                              1619712 Instructions   
     -Multi-Lane ALU Half Float Instructions                                                 0 Instructions   
     -Multi-Lane ALU Single Float Instructions                                          191808 Instructions   
     +Multi-Lane Matrix Instructions                                                         0 Instructions   
     +Multi-Lane 4-Pass Multiply Instructions                                           213120 Instructions   
     +SFU Instructions                                                                   63936 Instructions   
     +BFU Instructions                                                                 1534464 Instructions   
    ------------------------------------------------------------------------- ---------------- -------------
    INF: Statistics of Instructions issued and executed by the kernel.

    Section: Launch Statistics
    ------------------------------------------------------------------------- ---------------- -------------
    Grid Size                                                                      [333, 1, 1]                
    Block Size                                                                    [4096, 1, 1]                
    Launched Warps                                                                       21312 Warps          
    Threads                                                                            1363968 Threads        
    Scalar Register                                                                         21 Registers/Warp 
    Vector Register                                                                         10 Registers/Thread
    Dynamic Shared Memory                                                                    0 Bytes/Block    
    Static Shared Memory                                                                     0 Bytes/Block    
    ------------------------------------------------------------------------- ---------------- -------------
    INF: General information of Launch Statistics.

    Section: Memory Access
    ------------------------------------------------------------------------- ---------------- -------------
    LSU Utilization                                                                      97.42 %              
    LSU--Global Memory Utilization                                                       97.42 %              
    LSU--Shared Memory Utilization                                                         0.0 %              
    Global Memory Load Throughput                                                       559.72 MB/s           
    Global Memory Store Throughput                                                       17.49 GB/s           
    Shared Memory Load Throughput                                                          0.0 B/s            
    Shared Memory Store Throughput                                                         0.0 B/s            
    Shared Store Bank Conflict                                                               0 Conflicts      
    Shared Load Bank Conflict                                                                0 Conflicts      
    L1VK Unit Utilization                                                                24.71 %              
    L1 Vector Cache Load Hit Rate                                                          0.0 %              
    L1 Vector Cache Store Hit Rate                                                         0.0 %              
    L2 Cache Hit Rate                                                                      0.0 %              
    L2 Cache Access to Memory                                                          1406496 Requests       
    ------------------------------------------------------------------------- ---------------- -------------
    INF: Summary of Memory access operations.

    Section: Occupancy
    ------------------------------------------------------------------------- ---------------- -------------
    Achieved Active Warps Per CU                                                         86.85 Warps          
    Achieved Occupancy                                                                   67.85 %              
    Block Limit CU                                                                         128 Blocks         
    Block Limit VRF Per CU                                                                   6 Blocks         
    Block Limit SRF Per CU                                                                   6 Blocks         
    Block Limit Shared Mem Per CU                                                          128 Blocks         
    Block Limit Warps Per CU                                                                 2 Blocks         
    Theoretical Active Warps per CU                                                        128 Warps          
    Theoretical Occupancy                                                                100.0 %              
    Waves Per CU                                                                         10.41                
    ------------------------------------------------------------------------- ---------------- -------------
    INF: Occupancy is defined as the ratio of active warps on an NR to the maximum number(8) of active warps
supported by the NR.
    INF: Occupancy Limiters --- This kernel's theoretical occupancy is not impacted by any block limit. The
difference between calculated theoretical (100.0%) and measured achieved occupancy (67.85%) can be the
result of warp scheduling overheads or workload imbalances during the kernel execution.

  Kernel: void ker_weight_pad_trans<__half>(__half*, __half*, int), Context 1, Stream 1, correlationId 1096
    Section: GPU Speed Of Light
    ------------------------------------------------------------------------- ---------------- -------------
    Duration                                                                             13453 Ns             
    Elapsed Cycles                                                                      714368 Cycles         
    SPP Active Cycles                                                                   223706 Cycles         
    Scheduler(NS) Issue Cycles                                                           29522 Cycles         
    ALU Active Cycles                                                                    31721 Cycles         
    LSU Active Cycles                                                                    30349 Cycles         
    L1 Vector Cache Active Cycles                                                        19783 Cycles         
    ------------------------------------------------------------------------- ---------------- -------------
    INF: High-level overview of the usage for compute and memory resources of the GPU.
    WRN: Small Grid --- This kernel grid is too small to fill the available resources on this device, resulting
in only 0.38 full waves across all CUs. Look at [Launch Statistics] for more details.

    Section: Instruction Statistics
    ------------------------------------------------------------------------- ---------------- -------------
    Executed IPC                                                                      0.041730 Inst/Cycle     
    Executed Instructions                                                                29952 Instructions   
    Single-Lane Memory Instructions                                                       1536 Instructions   
    Single-Lane ALU Instructions                                                          7680 Instructions   
    Single-Lane Control Flow Instructions                                                  768 Instructions   
    Multi-Lane Memory Instructions                                                        1536 Instructions   
     -Multi-Lane Global Memory Instructions                                               1536 Instructions   
     -Multi-Lane Shared Memory Instructions                                                  0 Instructions   
     -Multi-Lane SME Memory Instructions                                                     0 Instructions   
    Multi-Lane ALU Instructions                                                          18432 Instructions   
     -Multi-Lane ALU Integer Instructions                                                18432 Instructions   
     -Multi-Lane ALU Half Float Instructions                                                 0 Instructions   
     -Multi-Lane ALU Single Float Instructions                                               0 Instructions   
     +Multi-Lane Matrix Instructions                                                         0 Instructions   
     +Multi-Lane 4-Pass Multiply Instructions                                              768 Instructions   
     +SFU Instructions                                                                       0 Instructions   
     +BFU Instructions                                                                   17664 Instructions   
    ------------------------------------------------------------------------- ---------------- -------------
    INF: Statistics of Instructions issued and executed by the kernel.

    Section: Launch Statistics
    ------------------------------------------------------------------------- ---------------- -------------
    Grid Size                                                                      [256, 3, 1]                
    Block Size                                                                       [3, 1, 1]                
    Launched Warps                                                                         768 Warps          
    Threads                                                                               2304 Threads        
    Scalar Register                                                                         11 Registers/Warp 
    Vector Register                                                                          5 Registers/Thread
    Dynamic Shared Memory                                                                    0 Bytes/Block    
    Static Shared Memory                                                                     0 Bytes/Block    
    ------------------------------------------------------------------------- ---------------- -------------
    INF: General information of Launch Statistics.
    WRN: Block Size --- Threads are executed in groups of 64 threads called warps. This kernel launch is
configured to execute 3 threads per block. Consequently, some threads in a warp are masked off and those
hardware resources are unused. Try changing the number of threads per block to be a multiple of 64 threads.
Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects
performance. This is particularly beneficial to kernels that frequently call __syncthreads(). 

    Section: Memory Access
    ------------------------------------------------------------------------- ---------------- -------------
    LSU Utilization                                                                       4.25 %              
    LSU--Global Memory Utilization                                                        4.25 %              
    LSU--Shared Memory Utilization                                                         0.0 %              
    Global Memory Load Throughput                                                         3.62 GB/s           
    Global Memory Store Throughput                                                       10.21 GB/s           
    Shared Memory Load Throughput                                                          0.0 B/s            
    Shared Memory Store Throughput                                                         0.0 B/s            
    Shared Store Bank Conflict                                                               0 Conflicts      
    Shared Load Bank Conflict                                                                0 Conflicts      
    L1VK Unit Utilization                                                                 2.77 %              
    L1 Vector Cache Load Hit Rate                                                        61.54 %              
    L1 Vector Cache Store Hit Rate                                                         0.0 %              
    L2 Cache Hit Rate                                                                    100.0 %              
    L2 Cache Access to Memory                                                                0 Requests       
    ------------------------------------------------------------------------- ---------------- -------------
    INF: Summary of Memory access operations.

    Section: Occupancy
    ------------------------------------------------------------------------- ---------------- -------------
    Achieved Active Warps Per CU                                                         21.67 Warps          
    Achieved Occupancy                                                                   16.93 %              
    Block Limit CU                                                                         128 Blocks         
    Block Limit VRF Per CU                                                                 128 Blocks         
    Block Limit SRF Per CU                                                                 128 Blocks         
    Block Limit Shared Mem Per CU                                                          128 Blocks         
    Block Limit Warps Per CU                                                               128 Blocks         
    Theoretical Active Warps per CU                                                        128 Warps          
    Theoretical Occupancy                                                                100.0 %              
    Waves Per CU                                                                          0.38                
    ------------------------------------------------------------------------- ---------------- -------------
    INF: Occupancy is defined as the ratio of active warps on an NR to the maximum number(8) of active warps
supported by the NR.
    INF: Occupancy Limiters --- This kernel's theoretical occupancy is not impacted by any block limit. The
difference between calculated theoretical (100.0%) and measured achieved occupancy (16.93%) can be the
result of warp scheduling overheads or workload imbalances during the kernel execution.

  Kernel: void ker_output_data<__half>(__half*, __half*), Context 1, Stream 1, correlationId 1147
    Section: GPU Speed Of Light
    ------------------------------------------------------------------------- ---------------- -------------
    Duration                                                                            337546 Ns             
    Elapsed Cycles                                                                    21466496 Cycles         
    SPP Active Cycles                                                                 20947343 Cycles         
    Scheduler(NS) Issue Cycles                                                         7196045 Cycles         
    ALU Active Cycles                                                                  8032555 Cycles         
    LSU Active Cycles                                                                 18657985 Cycles         
    L1 Vector Cache Active Cycles                                                      5199563 Cycles         
    ------------------------------------------------------------------------- ---------------- -------------
    INF: High-level overview of the usage for compute and memory resources of the GPU.
    INF: High Throughput --- The kernel is utilizing greater than 80% of the available compute or memory
performance of the device. To further improve performance, work will likely need to be shifted from the
most utilized to another unit. Start by analyzing workloads in the Memory Access section.

    Section: Instruction Statistics
    ------------------------------------------------------------------------- ---------------- -------------
    Executed IPC                                                                      0.374104 Inst/Cycle     
    Executed Instructions                                                              8027200 Instructions   
    Single-Lane Memory Instructions                                                     321088 Instructions   
    Single-Lane ALU Instructions                                                       2247616 Instructions   
    Single-Lane Control Flow Instructions                                               321088 Instructions   
    Multi-Lane Memory Instructions                                                      642176 Instructions   
     -Multi-Lane Global Memory Instructions                                             642176 Instructions   
     -Multi-Lane Shared Memory Instructions                                                  0 Instructions   
     -Multi-Lane SME Memory Instructions                                                     0 Instructions   
    Multi-Lane ALU Instructions                                                        4495232 Instructions   
     -Multi-Lane ALU Integer Instructions                                              4495232 Instructions   
     -Multi-Lane ALU Half Float Instructions                                                 0 Instructions   
     -Multi-Lane ALU Single Float Instructions                                               0 Instructions   
     +Multi-Lane Matrix Instructions                                                         0 Instructions   
     +Multi-Lane 4-Pass Multiply Instructions                                                0 Instructions   
     +SFU Instructions                                                                       0 Instructions   
     +BFU Instructions                                                                 4495232 Instructions   
    ------------------------------------------------------------------------- ---------------- -------------
    INF: Statistics of Instructions issued and executed by the kernel.

    Section: Launch Statistics
    ------------------------------------------------------------------------- ---------------- -------------
    Grid Size                                                                     [5017, 1, 1]                
    Block Size                                                                    [4096, 1, 1]                
    Launched Warps                                                                      321088 Warps          
    Threads                                                                           20549632 Threads        
    Scalar Register                                                                         10 Registers/Warp 
    Vector Register                                                                          5 Registers/Thread
    Dynamic Shared Memory                                                                    0 Bytes/Block    
    Static Shared Memory                                                                     0 Bytes/Block    
    ------------------------------------------------------------------------- ---------------- -------------
    INF: General information of Launch Statistics.

    Section: Memory Access
    ------------------------------------------------------------------------- ---------------- -------------
    LSU Utilization                                                                      86.92 %              
    LSU--Global Memory Utilization                                                       86.92 %              
    LSU--Shared Memory Utilization                                                         0.0 %              
    Global Memory Load Throughput                                                        113.4 GB/s           
    Global Memory Store Throughput                                                      226.79 GB/s           
    Shared Memory Load Throughput                                                          0.0 B/s            
    Shared Memory Store Throughput                                                         0.0 B/s            
    Shared Store Bank Conflict                                                               0 Conflicts      
    Shared Load Bank Conflict                                                                0 Conflicts      
    L1VK Unit Utilization                                                                24.22 %              
    L1 Vector Cache Load Hit Rate                                                          0.0 %              
    L1 Vector Cache Store Hit Rate                                                        50.0 %              
    L2 Cache Hit Rate                                                                      0.0 %              
    L2 Cache Access to Memory                                                          1284440 Requests       
    ------------------------------------------------------------------------- ---------------- -------------
    INF: Summary of Memory access operations.

    Section: Occupancy
    ------------------------------------------------------------------------- ---------------- -------------
    Achieved Active Warps Per CU                                                         52.21 Warps          
    Achieved Occupancy                                                                   40.79 %              
    Block Limit CU                                                                         128 Blocks         
    Block Limit VRF Per CU                                                                  12 Blocks         
    Block Limit SRF Per CU                                                                  12 Blocks         
    Block Limit Shared Mem Per CU                                                          128 Blocks         
    Block Limit Warps Per CU                                                                 2 Blocks         
    Theoretical Active Warps per CU                                                        128 Warps          
    Theoretical Occupancy                                                                100.0 %              
    Waves Per CU                                                                        156.78                
    ------------------------------------------------------------------------- ---------------- -------------
    INF: Occupancy is defined as the ratio of active warps on an NR to the maximum number(8) of active warps
supported by the NR.
    INF: Occupancy Limiters --- This kernel's theoretical occupancy is not impacted by any block limit. The
difference between calculated theoretical (100.0%) and measured achieved occupancy (40.79%) can be the
result of warp scheduling overheads or workload imbalances during the kernel execution.

